---
title: I Built a Full AI-Ready Design System in 1.4 Days. With AI.
description: "I Built a Full AI-Ready Design System in 1.4 Days. With AI.
And why this matters far more than you think for the future of energy."
author: Paul Cooper
publishDate: 2026-01-06
category: insights
featuredImage: /blog/images/i-built-a-full-ai-ready-design-Kq2jAtpAYQzNygvv6ODbLw9ZEUQ.png
slug: i-built-a-full-ai-ready-design-system-in-1-4-days-with-ai
locale: en
---

**I Built a Full AI-Ready Design System in 1.4 Days. With AI.And why this matters far more than you think for the future of energy.
Last week, I did something that would have taken months just two years ago. In roughly 34 hours of actual work, spread across 1.4 days, I built and deployed a comprehensive design system for our team at Sourceful Energy - complete with 50+ production-ready components, automated roadmaps, GitHub feedback loops, and full AI integration.

The tool I used to build it? Claude Code. The irony isn't lost on me.

But this isn't a humble-brag about productivity hacks. This is a story about where all that computational power actually comes from, where the real AI opportunity lies, and why a Swedish energy startup might be building some of the most important technology of the next decade.

## What We Actually Built

Before diving into the bigger picture, let me show you what's possible when AI-assisted development goes from gimmick to genuine force multiplier.

The [Sourceful Design System](https://design.sourceful.energy/) is a complete internal toolkit built to help our team ship consistent, accessible interfaces across all our energy products. It includes:

**50+ React Components**: Production-ready components built with Radix UI and Tailwind CSS. Everything from complex data visualisation components-live energy flow diagrams, real-time monitoring dashboards, fleet management tables-to foundational elements like buttons, inputs, and cards.

**Design Tokens System**: Consistent colours, typography, spacing, and shadows implemented as CSS variables that work everywhere. Our energy-focused palette captures everything from solar production yellows to battery charge blues.

**AI-First Architecture**: Here's where it gets meta. The system includes a built-in Claude Code prompt and a downloadable `CLAUDE.md` template. When any team member starts a new project, Claude automatically knows how to use our design system correctly:

```bash
curl -o CLAUDE.md https://raw.githubusercontent.com/srcfl/srcful-design-system/main/CLAUDE.project-template.md
```

**Live Component Previews**: Interactive demonstrations showing real energy management scenarios-sites monitoring, savings calculations, EV charging status, weather-adjusted forecasting, and dynamic electricity pricing displays.

**Automated Feedback Loops**: GitHub integration allowing the team to suggest improvements, report issues, and contribute directly to an auto-generated roadmap.

The entire system is open source under MIT license. But what struck me during the build wasn't just the speed - it was the realisation of where all this AI capability actually comes from.

## The Trillion-Dollar Merry-Go-Round

Here's the uncomfortable truth about the current AI boom that more people should be talking about.

In September 2025, Nvidia announced it would invest up to $100 billion in OpenAI. The stated purpose? To fund a new generation of data centres. What OpenAI pledged in return? To purchase millions of Nvidia chips for those facilities.

This isn't investment in the traditional sense. This is a company paying its customer to buy more of its products.

The pattern repeats throughout the ecosystem. Nvidia invested in CoreWeave, a data centre operator that rents GPU capacity back to OpenAI. OpenAI signed deals with CoreWeave worth over $22 billion, paying in part with stock that CoreWeave can use to buy more Nvidia chips. Meanwhile, Microsoft gave OpenAI funding and cloud credits; OpenAI drives Azure usage; Microsoft buys more Nvidia GPUs for its data centres.

As The Register aptly described it: "Money, computer chips, and cloud credits are rotating in a closed loop among a handful of companies."

NewStreet Research estimated that for every $10 billion Nvidia invests in OpenAI, it sees $35 billion worth of GPU purchases in return. That's a 3.5x multiplier on what is essentially vendor financing dressed up as investment.

The numbers are staggering. Between 2020 and 2025, Nvidia invested roughly $53 billion across 170 deals spanning the AI ecosystem. In 2024 alone, it deployed $23.7 billion through 59 deals. Even Michael Burry - the investor who predicted the 2008 financial crisis - weighed in, noting that "true end demand is ridiculously small" and that "almost all customers are funded by their dealers."

Sam Altman himself acknowledged the froth. When asked if investors were overexcited about AI, his response was telling: "My opinion is yes. Is AI the most important thing to happen in a very long time? My opinion is also yes."

Both things can be true. The technology is transformative. The financing is precarious.

## Claude Code and the Democratisation of Building

Yet here I am, having built a complete design system in less than two days. The productive potential is undeniable.

Claude Code has exploded since becoming generally available in May 2025. The tool hit $1 billion in run-rate revenue by November - just six months after public launch. Usage grew 10x in three months. It now serves hundreds of thousands of developers, with companies like Netflix, Spotify, KPMG, L'Oréal, and Salesforce among its enterprise clients.

Anthropic's internal research shows engineers delegating increasingly complex work to Claude, with task complexity ratings rising from 3.2 to 3.8 on their 1-5 scale. The number of human turns per session decreased while the maximum consecutive tool calls increased. People are handing over more autonomy to AI, and it's working.

For small teams like ours at Sourceful - where a junior designer and I handle everything from product design to performance marketing - this represents a fundamental capability shift. We can now build internal tools, maintain comprehensive documentation, and ship features that would have required a dedicated engineering team.

The explosion extends beyond Claude. The entire AI coding assistant market has grown into a multi-billion dollar space. Developers can prototype in hours what previously took weeks. Non-technical founders can build functional MVPs. Solo creators can maintain codebases that rival small companies.

But all of this computation has to run somewhere. And that somewhere is increasingly hungry.

## The Layer Below the Layer Below

When discussing AI investment opportunities, most attention focuses on the obvious plays: the foundation model companies (OpenAI, Anthropic, Google DeepMind), the infrastructure providers (AWS, Azure, GCP), the chip makers (Nvidia, AMD, Intel), and the enabling hardware (storage, networking, cooling).

But there's a layer below all of these that receives far less attention: **energy**.

The International Energy Agency projects that global data centre electricity consumption will grow by 15% annually through 2030 - more than four times faster than total electricity growth from all other sectors combined. By the end of the decade, data centres will consume around 945 TWh annually, equivalent to Japan's entire current electricity demand.

AI is the primary driver. Electricity consumption in accelerated servers (meaning AI workloads) is projected to grow 30% annually, versus just 9% for conventional servers. AI already accounts for 5-15% of data centre power use; that could reach 35-50% by 2030.

The geographic concentration is striking. Nearly 80% of the growth will occur in the US and China. American data centres already consume 183 TWh annually - more than 4% of national electricity demand - and that's projected to reach 426 TWh by 2030, a 133% increase.

RAND Corporation estimates AI data centres could need 68 gigawatts of power capacity by 2027 - almost California's entire 2022 capacity. OpenAI's Stargate initiative alone plans to build 10 gigawatts of data centres, requiring as much electricity as New York City during summer peak demand.

The strain is already visible. Wholesale electricity prices near data centre hotspots have increased by as much as 267% since 2020. In the PJM electricity market spanning Illinois to North Carolina, data centres contributed to a $9.3 billion price increase in the 2025-26 capacity market. Residential customers in parts of Maryland and Ohio are seeing monthly bill increases of $16-18 as a direct result.

This is where the real AI investment thesis becomes clear. It's not about which model wins or which coding assistant gets the most adoption. It's about who controls the energy infrastructure that makes any of this possible.

## What Sourceful Is Actually Building

This brings me back to why I was building a design system in the first place.

Sourceful Energy isn't an AI company in the traditional sense. We're an energy coordination platform, building the infrastructure to connect distributed energy resources - home solar systems, batteries, EVs, smart metres - into a coherent, intelligent network.

The core problem we solve: electricity grids were designed for centralised, one-directional power flow. Power plants generate; homes consume. But that model is crumbling. Solar panels on roofs generate power. EV batteries can discharge back to homes. Home batteries can arbitrage price differences. The grid is becoming bidirectional, distributed, and vastly more complex.

Our [Sourceful Zap](https://www.sourceful.energy/) device connects to smart metres and solar inverters, enabling real-time monitoring, automated optimisation, and grid coordination. For €39, homeowners can track their energy usage, avoid peak demand charges, and protect against negative pricing on solar exports.

But the real opportunity -and why this connects to everything above - is what happens when you aggregate thousands of these connected devices.

A single home battery is interesting. Ten thousand home batteries coordinated as a virtual power plant is transformative. The collective capacity of distributed energy resources in residential settings already exceeds many traditional power plants. The challenge has been coordination - knowing what's available, when, and orchestrating it in real-time.

This is precisely what AI data centres need: flexible, distributed power capacity that can ramp up and down on demand. The irony is perfect. AI creates the coordination challenge, and AI helps solve it.

## The Inverted Opportunity

Most conversations about AI investment focus on riding the compute wave - buying Nvidia, investing in foundation models, backing infrastructure plays. The smarter money is thinking about what constrains the wave.

Grid operators are already turning away data centres because they don't have sufficient power. Renewable energy - particularly solar and battery storage - represents the fastest path to new capacity. More than 90% of power projects currently waiting for grid connection are solar, battery storage, or wind.

But renewable generation is intermittent. Solar produces when the sun shines, not necessarily when data centres need it. Wind generates when it blows. The missing piece is coordination and storage - exactly what a network of distributed batteries provides.

This isn't speculation. Multiple tech companies have announced purchasing agreements with nuclear power startups. Plans are underway to revive retired nuclear plants specifically to serve data centre demand. The power constraint is real enough that it's reshaping energy policy.

Our bet is that distributed coordination scales faster and more flexibly than centralised generation. A network of 100,000 home batteries, intelligently coordinated, can provide services that a single power plant cannot: geographic distribution, demand flexibility, local resilience.

## The Point

I built a design system in 1.4 days. It's good- genuinely useful for our team, accelerating our development velocity, ensuring consistency across everything we ship.

But the tools that enabled this - Claude Code, the broader AI infrastructure, the computational resources behind it-rest on an increasingly strained foundation. The money flowing through the AI ecosystem may be circular, but the electricity demand is very real.

Somewhere between the trillion-dollar financing loops and the 68 gigawatts of projected demand lies an opportunity that most people are missing. The AI boom isn't just about models and chips and cloud credits. It's about joules and kilowatt-hours and grid capacity.

At Sourceful, we're not building AI in the conventional sense. We're building what AI needs to exist at all.

The Sourceful Design System is available at *[*design.sourceful.energy*](https://design.sourceful.energy/)*. Learn more about our energy coordination platform at *[*sourceful.energy*](https://www.sourceful.energy/)*.*

*Yes I used Claude to write this blog post*
